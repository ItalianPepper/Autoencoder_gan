{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "easy_vaegan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ItalianPepper/VAE-GAN/blob/master/easy_vaegan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cShMCBv6XnVd"
      },
      "source": [
        "# Some reference\n",
        "- Gan trained by TTUR : https://arxiv.org/abs/1706.08500\n",
        "- Keras problem with trainable: https://github.com/keras-team/keras/issues/9589\n",
        "- VAEGAN https://github.com/crmaximo/VAEGAN\n",
        "- VAEGAN original : https://arxiv.org/pdf/1512.09300.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRoJdYrbjTUT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzLNqwDumbSH"
      },
      "source": [
        "# Unzip a limited number of file\n",
        "!unzip -Z1 \"/content/drive/My Drive/GAN/img_align_celeba.zip\" | head -10001 | sed 's| |\\\\ |g' | xargs unzip \"/content/drive/My Drive/GAN/img_align_celeba.zip\" -d ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCdLT1QhtXV-"
      },
      "source": [
        "!mkdir ./res_gan_autoencoder"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNvY5gNnwN0p",
        "outputId": "186043ec-09b2-4f34-fa2b-70c5ace5aba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from random import shuffle\n",
        "from tensorflow.keras import metrics, backend as K\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "\n",
        "def get_dataset(path, img_shape):\n",
        "    paths = []\n",
        "\n",
        "    valid_format = [\".jpg\", \".png\", \".tiff\", \".bmp\", \".gif\"]\n",
        "\n",
        "    for img in os.listdir(path):\n",
        "\n",
        "        extension = os.path.splitext(img)[1]\n",
        "\n",
        "        if extension.lower() in valid_format:\n",
        "            paths.append(os.path.join(path, img))\n",
        "\n",
        "    k_train = []\n",
        "\n",
        "    for path_image in paths:\n",
        "        img = load_img(path_image, target_size=img_shape[:2])\n",
        "        \n",
        "        el = img_to_array(img) / 255.0\n",
        "        \n",
        "        k_train.append(el)\n",
        "\n",
        "    k_train = np.asarray(k_train)\n",
        "\n",
        "    return k_train\n",
        "\n",
        "  \n",
        "def get_noise(n_sample=1, nlatent_dim=512):\n",
        "    noise = np.random.normal(0, 1, (n_sample, nlatent_dim))\n",
        "    return (noise)\n",
        "  \n",
        "\n",
        "def plot_generated_images(noise, nsample=1, path_save=None, epoch=0):\n",
        "    imgs = decoder.predict(noise)\n",
        "    img = imgs[0]\n",
        "    \n",
        "    # Solution: \"Clipping input data to the valid range for imshow \n",
        "    # with RGB data ([0..1] for floats or [0..255] for integers).\"\n",
        "    \n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    \n",
        "    fig = plt.figure(figsize=(40, 10))\n",
        "    fig.patch.set_visible(False)\n",
        "    epoch_str = str(epoch)\n",
        "    extension = \".png\"\n",
        "    path_name = path_save + \"/\" + epoch_str + extension\n",
        "    \n",
        "    ax = fig.add_subplot(1, nsample, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    \n",
        "    #fig.suptitle(\"Epoch:\" + epoch_str, fontsize=30)\n",
        "    \n",
        "    plt.savefig(path_name,\n",
        "                bbox_inches='tight',\n",
        "                pad_inches=0)\n",
        "    \n",
        "    plt.close()\n",
        "\n",
        "def build_encoder(img_shape):\n",
        "    input_img = Input(shape=img_shape, name=\"input_encoder\")\n",
        "    n_filter = 32\n",
        "    \n",
        "    # Encoding\n",
        "    x = Conv2D(n_filter, kernel_size=(3, 3), padding=\"same\")(input_img)\n",
        "    x = BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = MaxPooling2D(padding='same')(x)\n",
        "    \n",
        "    x = Conv2D(n_filter*4, kernel_size=(3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = MaxPooling2D(padding='same')(x)\n",
        "    \n",
        "    x = Conv2D(n_filter*8, kernel_size=(3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = MaxPooling2D(padding='same')(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    logsigma = Dense(512, activation=\"tanh\")(x)\n",
        "    \n",
        "    model = Model(inputs=input_img, outputs=logsigma)\n",
        "    # model.summary()\n",
        "    return (model)\n",
        "  \n",
        "def build_decoder_gen(en_shape=(512,)):\n",
        "    # impostazione del generatore\n",
        "    en_img = Input(shape=en_shape, name=\"input_decoder\")\n",
        "    img_dim = 32 * 16\n",
        "    n_filter = 32\n",
        "    \n",
        "    x = Dense(img_dim*8*8)(en_img)\n",
        "    x = Reshape((8,8,img_dim))(x)\n",
        "    x = BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # x = Activation(\"relu\")(x)\n",
        "    \n",
        "    # Decoding\n",
        "    x = Conv2D(n_filter*4, kernel_size=(3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    #x = Activation(\"relu\")(x)\n",
        "    x = UpSampling2D()(x)\n",
        "    \n",
        "    x = Conv2D(n_filter*2, kernel_size=(3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    #x = Activation(\"relu\")(x)\n",
        "    x = UpSampling2D()(x)\n",
        "    \n",
        "    x = Conv2D(n_filter, kernel_size=(3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    #x = Activation(\"relu\")(x)\n",
        "    x = UpSampling2D()(x)\n",
        "\n",
        "    x = Conv2D(3, kernel_size=(3, 3), padding=\"same\")(x)\n",
        "    x = Activation('tanh')(x)\n",
        "    \n",
        "    model = Model(inputs=en_img, outputs=x)\n",
        "    # model.summary()\n",
        "    return (model)\n",
        "  \n",
        "def build_discriminator(img_shape):\n",
        "  \n",
        "    input_img = Input(shape=img_shape, name=\"input_discriminator\")\n",
        "    n_filter = 32\n",
        "    \n",
        "    x = Conv2D(n_filter, kernel_size=(3, 3), padding='same', strides=2)(input_img)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    \n",
        "    x = Conv2D(n_filter*2, kernel_size=(3, 3), padding='same', strides=2)(x)\n",
        "    x = BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    \n",
        "    x = Conv2D(n_filter*4, kernel_size=(3, 3), padding='same', strides=2)(x)\n",
        "    x = BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    \n",
        "    x = Conv2D(128, kernel_size=(3, 3), padding='same', strides=2)(x)\n",
        "    \n",
        "    x = BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=input_img, outputs=out)\n",
        "\n",
        "    # model.summary()\n",
        "    return model\n",
        "  \n",
        "  \n",
        "def train(encoder, decoder, discriminator, enc_dec, x_train,\n",
        "          dir_result=\"./\", epochs=10000, batch_size=512):\n",
        "   \n",
        "    history = []\n",
        "    \n",
        "    if epochs >= 100:\n",
        "      checkpoint = int(epochs/10)\n",
        "    else:\n",
        "      checkpoint = 1\n",
        "    \n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "      \n",
        "        start_epoch = time.time()\n",
        "        \n",
        "        np.random.shuffle(x_train)\n",
        "        \n",
        "        batches_index = [x for x in range(0, len(x_train), batch_size)]\n",
        "        \n",
        "        for i in range(0, len(batches_index)):\n",
        "          \n",
        "          start = batches_index[i]\n",
        "          \n",
        "          if i == len(batches_index)-1:\n",
        "            end = len(x_train)\n",
        "          else:\n",
        "            end = batches_index[i+1]\n",
        "            \n",
        "          x_batch = x_train[start:end]\n",
        "          x_batch_size = len(x_batch)\n",
        "          \n",
        "          \n",
        "          # encoder e decoder su immagini reali\n",
        "          gen_img_enc = encoder.predict(x_batch)\n",
        "          gen_img_dec = decoder.predict(gen_img_enc)\n",
        "\n",
        "          noise = get_noise(n_sample=x_batch_size)\n",
        "          # immagini create dal noise\n",
        "          fake_img = decoder.predict(noise)\n",
        "\n",
        "          # Allenamento encoder - decoder\n",
        "          enc_dec_loss = enc_dec.train_on_batch(x_batch, x_batch)\n",
        "\n",
        "          # Allenamento solo decoder\n",
        "          noise_gen = get_noise(n_sample=x_batch_size)\n",
        "          decoder_noise_loss = decoder.train_on_batch(noise_gen, x_batch)\n",
        "\n",
        "          matrix_true = np.ones((x_batch_size, 1))\n",
        "          matrix_false = np.zeros((x_batch_size, 1))\n",
        "          \n",
        "          # Allenamento discriminatore\n",
        "          dsc_true = discriminator.train_on_batch(x_batch, matrix_true)\n",
        "          dsc_true_enc = discriminator.train_on_batch(gen_img_dec, matrix_true)\n",
        "          dsc_fake = discriminator.train_on_batch(fake_img, matrix_false)\n",
        "\n",
        "        if epoch % checkpoint == 0 and epoch > 0:\n",
        "          history.append({\"Epoch:\": epoch,\n",
        "                          \"Discriminator_loss_true:\": dsc_true[0],\n",
        "                          \"Discriminator_loss_true_enc:\": dsc_true_enc[0],\n",
        "                          \"Discriminator_loss_fake\": dsc_fake[0],\n",
        "                          \"Discriminator_acc_fake\": dsc_fake[1],\n",
        "                          \"Encoder-Decoder:\": enc_dec_loss,\n",
        "                          \"Decoder_noise_loss:\": decoder_noise_loss,\n",
        "                          })\n",
        "\n",
        "          noise = get_noise(n_sample=1)\n",
        "\n",
        "          plot_generated_images(noise, 1, dir_result, epoch)\n",
        "\n",
        "        end_epoch = time.time()\n",
        "        end_epoch = end_epoch - start_epoch\n",
        "        print(\"Ended Epoch {:0.0f}/{:1.0f} in: {:2.4f} s\".format(epoch + 1, epochs, end_epoch))\n",
        "\n",
        "    return history\n",
        "\n",
        "def gan_loss(real_val, generated_val):\n",
        "  def loss(y_true, y_pred):\n",
        "    return K.log((real_val)) + K.log(1-generated_val)\n",
        "  return loss\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "img_shape = (64, 64, 3)\n",
        "noise_shape = (512,)\n",
        "optimizer_std = SGD(0.0003)\n",
        "optimizer_disc = SGD(0.0004)\n",
        "\n",
        "pre_trained = False\n",
        "path_load_models = \"./drive/My Drive/GAN/train_2_img_celeba/models/\"\n",
        "\n",
        "if pre_trained == False:\n",
        "\n",
        "  encoder = build_encoder(img_shape)\n",
        "  decoder = build_decoder_gen(noise_shape)\n",
        "  discriminator = build_discriminator(img_shape)\n",
        "\n",
        "  encoder.compile(loss=\"mse\", optimizer=optimizer_std)\n",
        "  decoder.compile(loss=\"mse\", optimizer=optimizer_std)\n",
        "\n",
        "  discriminator.compile(loss=\"mse\",\n",
        "                              optimizer=optimizer_disc,\n",
        "                              metrics=[\"accuracy\"])\n",
        "\n",
        "  x_img = Input(shape=img_shape)\n",
        "\n",
        "  enc_img = encoder(x_img)\n",
        "\n",
        "  dec_img = decoder(enc_img)\n",
        "\n",
        "  enc_dec = Model(inputs = [x_img], outputs = [dec_img])\n",
        "\n",
        "  enc_dec.compile(loss=\"mse\", optimizer=optimizer_std)\n",
        "\n",
        "  #enc_dec.summary()\n",
        "\n",
        "  # Wrapping first model (enc_dec) in the second (gan)\n",
        "\n",
        "  x_1 = Input(shape=img_shape)\n",
        "  x_2 = Input(shape=noise_shape)\n",
        "\n",
        "  d_img = enc_dec([x_1])\n",
        "  g_img = decoder([x_2])\n",
        "\n",
        "  true_el = discriminator(x_1)\n",
        "  true_gen = discriminator(d_img)\n",
        "  fake_img = discriminator(g_img)\n",
        "\n",
        "  gan = Model(inputs=[x_1, x_2], outputs=[true_el, fake_img])\n",
        "\n",
        "  gan.compile(loss=gan_loss(true_el, fake_img), optimizer=optimizer_std)\n",
        "\n",
        "  gan.summary()\n",
        "\n",
        "else:\n",
        "  encoder = load_model(path_load_models+\"encoder.h5\")\n",
        "  decoder = load_model(path_load_models+\"decoder.h5\")\n",
        "  discriminator = load_model(path_load_models+\"discriminator.h5\")\n",
        "  enc_dec = load_model(path_load_models+ \"enc_dec.h5\")\n",
        "  gan = load_model(path_load_models+\"gan_autoencoder.h5\")\n",
        "  \n",
        "\n",
        "x_train = get_dataset(\"./img_align_celeba\", img_shape)\n",
        "\n",
        "path = \"./res_gan_autoencoder/\"\n",
        "\n",
        "history = train(encoder, decoder, discriminator, enc_dec, x_train,\n",
        "                dir_result=path, epochs=101, batch_size=128)\n",
        "\n",
        "with open(path+\"log_gan.txt\", \"w\") as f:\n",
        "  for item in history:\n",
        "    item_str = str(item) + \"\\n\"\n",
        "    f.write(item_str)\n",
        "    \n",
        "discriminator.trainable = True\n",
        "\n",
        "encoder.save(path+\"encoder.h5\", save_format=\"tf\")\n",
        "decoder.save(path+\"decoder.h5\", save_format=\"tf\")\n",
        "discriminator.save(path+\"discriminator.h5\", save_format=\"tf\")\n",
        "enc_dec.save(path+\"enc_dec.h5\", save_format=\"tf\")\n",
        "gan.save(path+\"gan_autoencoder.h5\", save_format=\"tf\")\n",
        "\n",
        "end = time.time()\n",
        "end = end - start\n",
        "print(\"Finished in: \" + str(end) + \" s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_165\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_59 (InputLayer)           [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_58 (InputLayer)           [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "functional_159 (Functional)     (None, 64, 64, 3)    17496003    input_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_161 (Functional)     (None, 1)            244161      input_58[0][0]                   \n",
            "                                                                 functional_159[2][0]             \n",
            "==================================================================================================\n",
            "Total params: 17,740,164\n",
            "Trainable params: 17,738,052\n",
            "Non-trainable params: 2,112\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f2d68be62f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f2d69024620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f2d5e755950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Ended Epoch 1/101 in: 122.6884 s\n",
            "Ended Epoch 2/101 in: 120.5804 s\n",
            "Ended Epoch 3/101 in: 121.9749 s\n",
            "Ended Epoch 4/101 in: 122.6564 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4aBNjOjCqJr"
      },
      "source": [
        "!rm -r ./img_align_celeba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWlMvZnpMi-Y"
      },
      "source": [
        "!rm -r ./res_gan_autoencoder"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}